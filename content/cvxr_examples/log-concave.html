---
title: Log-Concave Distribution Estimation
author: Anqi Fu and Balasubramanian Narasimhan
date: '2017-11-02'
slug: cvxr_log-concave
bibliography: ../bibtex/cvxr_refs.bib
link-citations: true
categories: []
tags: []
params:
  mode: ignore
  testdata_dir: test_data_1.0
  data_dir: log-concave
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Let <span class="math inline">\(n = 1\)</span> and suppose <span class="math inline">\(x_i\)</span> are i.i.d. samples from a log-concave
discrete distribution on <span class="math inline">\(\{0,\ldots,K\}\)</span> for some
<span class="math inline">\(K \in {\mathbf Z}_+\)</span>. Define <span class="math inline">\(p_k := {\mathbf {Prob}}(X = k)\)</span> to be the
probability mass function. One method for estimating
<span class="math inline">\(\{p_0,\ldots,p_K\}\)</span> is to maximize the log-likelihood function
subject to a log-concavity constraint , i.e.,</p>
<p><span class="math display">\[
\begin{array}{ll}
\underset{p}{\mbox{maximize}} &amp; \sum_{k=0}^K M_k\log p_k \\
\mbox{subject to} &amp; p \geq 0, \quad \sum_{k=0}^K p_k = 1, \\
&amp; p_k \geq \sqrt{p_{k-1}p_{k+1}}, \quad k = 1,\ldots,K-1,
\end{array}
\]</span></p>
<p>where <span class="math inline">\(p \in {\mathbf R}^{K+1}\)</span> is our variable of interest and <span class="math inline">\(M_k\)</span>
represents the number of observations equal to <span class="math inline">\(k\)</span>, so that
<span class="math inline">\(\sum_{k=0}^K M_k = m\)</span>. The problem as posed above is not
convex. However, we can transform it into a convex optimization
problem by defining new variables <span class="math inline">\(u_k = \log p_k\)</span> and relaxing the
equality constraint to <span class="math inline">\(\sum_{k=0}^K p_k \leq 1\)</span>, since the latter
always holds tightly at an optimal solution. The result is</p>
<p><span class="math display">\[
\begin{array}{ll}
\underset{u}{\mbox{maximize}} &amp; \sum_{k=0}^K M_k u_k \\
\mbox{subject to} &amp; \sum_{k=0}^K e^{u_k} \leq 1, \\
&amp; u_k - u_{k-1} \geq u_{k+1} - u_k, \quad k = 1,\ldots,K-1.
\end{array}
\]</span></p>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>We draw <span class="math inline">\(m = 25\)</span> observations from a log-concave distribution on
<span class="math inline">\(\{0,\ldots,100\}\)</span>. We then estimate the probability mass function
using the above method and compare it with the empirical distribution.</p>
<pre class="r"><code>set.seed(1)
## Calculate a piecewise linear function
pwl_fun &lt;- function(x, knots) {
    n &lt;- nrow(knots)
    x0 &lt;- sort(knots$x, decreasing = FALSE)
    y0 &lt;- knots$y[order(knots$x, decreasing = FALSE)]
    slope &lt;- diff(y0)/diff(x0)
    
    sapply(x, function(xs) {
        if(xs &lt;= x0[1])
            y0[1] + slope[1]*(xs -x0[1])
        else if(xs &gt;= x0[n])
            y0[n] + slope[n-1]*(xs - x0[n])
        else {
            idx &lt;- which(xs &lt;= x0)[1]
            y0[idx-1] + slope[idx-1]*(xs - x0[idx-1])
        }
    })
}
## Problem data
m &lt;- 25
xrange &lt;- 0:100
knots &lt;- data.frame(x = c(0, 25, 65, 100), y = c(10, 30, 40, 15))
xprobs &lt;- pwl_fun(xrange, knots)/15
xprobs &lt;- exp(xprobs)/sum(exp(xprobs))
x &lt;- sample(xrange, size = m, replace = TRUE, prob = xprobs)

K &lt;- max(xrange)
counts &lt;- hist(x, breaks = -1:K, right = TRUE, include.lowest = FALSE,
               plot = FALSE)$counts</code></pre>
<pre class="r"><code>ggplot() +
    geom_histogram(mapping = aes(x = x), breaks = -1:K, color = &quot;blue&quot;, fill = &quot;orange&quot;)</code></pre>
<p><img src="/cvxr_examples/log-concave_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We now solve problem with log-concave constraint.</p>
<pre class="r"><code>u &lt;- Variable(K+1)
obj &lt;- t(counts) %*% u
constraints &lt;- list(sum(exp(u)) &lt;= 1, diff(u[1:K]) &gt;= diff(u[2:(K+1)]))
prob &lt;- Problem(Maximize(obj), constraints)
result &lt;- solve(prob)
pmf &lt;- result$getValue(exp(u))</code></pre>
<p>The above lines transform the variables <span class="math inline">\(u_k\)</span> to <span class="math inline">\(e^{u_k}\)</span> before
calculating their resulting values. This is possible because <code>exp</code> is
a member of the <code>CVXR</code> library of atoms, so it can operate directly on
a <code>Variable</code> object such as <code>u</code>.</p>
<p>Below are the comparison plots of pmf and cdf.</p>
<pre class="r"><code>dens &lt;- density(x, bw = &quot;sj&quot;)
d &lt;- data.frame(x = xrange, True = xprobs, Optimal = pmf,
                Empirical = approx(x = dens$x, y = dens$y, xout = xrange)$y)
plot.data &lt;- gather(data = d, key = &quot;Type&quot;, value = &quot;Estimate&quot;, True, Empirical, Optimal,
                    factor_key = TRUE)
ggplot(plot.data) +
    geom_line(mapping = aes(x = x, y = Estimate, color = Type)) +
    theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="/cvxr_examples/log-concave_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>d &lt;- data.frame(x = xrange, True = cumsum(xprobs),
                Empirical = cumsum(counts) / sum(counts),
                Optimal = cumsum(pmf))
plot.data &lt;- gather(data = d, key = &quot;Type&quot;, value = &quot;Estimate&quot;, True, Empirical, Optimal,
                    factor_key = TRUE)
ggplot(plot.data) +
    geom_line(mapping = aes(x = x, y = Estimate, color = Type)) +
    theme(legend.position = &quot;top&quot;)</code></pre>
<p><img src="/cvxr_examples/log-concave_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>From the figures we see that the estimated curve is much closer to the
true distribution, exhibiting a similar shape and number of peaks. In
contrast, the empirical probability mass function oscillates, failing
to be log-concave on parts of its domain. These differences are
reflected in the cumulative distribution functions as well.</p>
</div>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.0.2 (2020-06-22)
## Platform: x86_64-apple-darwin19.5.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS/LAPACK: /usr/local/Cellar/openblas/0.3.10_1/lib/libopenblasp-r0.3.10.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices datasets  utils     methods   base     
## 
## other attached packages:
## [1] tidyr_1.1.0   ggplot2_3.3.2 CVXR_1.0-9   
## 
## loaded via a namespace (and not attached):
##  [1] gmp_0.6-0        Rcpp_1.0.5       compiler_4.0.2   pillar_1.4.6    
##  [5] tools_4.0.2      digest_0.6.25    bit_1.1-15.2     evaluate_0.14   
##  [9] lifecycle_0.2.0  tibble_3.0.3     gtable_0.3.0     lattice_0.20-41 
## [13] pkgconfig_2.0.3  rlang_0.4.7      Matrix_1.2-18    gurobi_9.0.3.1  
## [17] Rglpk_0.6-4      yaml_2.2.1       blogdown_0.19    xfun_0.15       
## [21] cccp_0.2-4       ECOSolveR_0.5.3  withr_2.2.0      dplyr_1.0.0     
## [25] Rmpfr_0.8-1      stringr_1.4.0    knitr_1.28       generics_0.0.2  
## [29] vctrs_0.3.2      tidyselect_1.1.0 bit64_0.9-7      grid_4.0.2      
## [33] glue_1.4.1       R6_2.4.1         rmarkdown_2.3    bookdown_0.19   
## [37] farver_2.0.3     purrr_0.3.4      magrittr_1.5     codetools_0.2-16
## [41] rcbc_0.1.0.9001  scales_1.1.1     htmltools_0.5.0  ellipsis_0.3.1  
## [45] assertthat_0.2.1 colorspace_1.4-1 labeling_0.3     Rcplex_0.3-3    
## [49] stringi_1.4.6    Rmosek_9.2.3     munsell_0.5.0    slam_0.1-47     
## [53] crayon_1.3.4</code></pre>
</div>
<div id="source" class="section level2">
<h2>Source</h2>
<p><a href="https://github.com/bnaras/cvxr_docs/blob/master/content/cvxr_examples/log-concave.Rmd">R Markdown</a></p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
</div>
