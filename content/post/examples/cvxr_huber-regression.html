---
title: Huber Regression
author: Anqi Fu and Balasubramanian Narasimhan
date: '2017-11-02'
slug: cvxr_huber-regression
bibliography: ../bibtex/cvxr_refs.bib
link-citations: true
categories: []
tags: []
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Huber regression <span class="citation">(Huber <a href="#ref-Huber:1964">1964</a>)</span> is a regression technique that is robust to outliers. The idea is to use a different loss function rather than the traditional least-squares; we solve</p>
<span class="math display">\[\begin{array}{ll} 
\underset{\beta}{\mbox{minimize}} &amp; \sum_{i=1}^m \phi(y_i -
x_i^T\beta) 
\end{array}\]</span>
<p>for variable <span class="math inline">\(\beta \in {\mathbf R}^n\)</span>, where the loss <span class="math inline">\(\phi\)</span> is the Huber function with threshold <span class="math inline">\(M &gt; 0\)</span>, <span class="math display">\[
    \phi(u) = 
    \begin{cases}
        u^2 &amp; \mbox{if } |u| \leq M \\
        2Mu - M^2 &amp; \mbox{if } |u| &gt; M.
    \end{cases}
\]</span></p>
<p>This function is identical to the least squares penalty for small residuals, but on large residuals, its penalty is lower and increases linearly rather than quadratically. It is thus more forgiving of outliers.</p>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<p>We generate some problem data.</p>
<pre class="r"><code>n &lt;- 1
m &lt;- 450
M &lt;- 1      ## Huber threshold
p &lt;- 0.1    ## Fraction of responses with sign flipped

## Generate problem data
set.seed(1289)
beta_true &lt;- 5 * matrix(stats::rnorm(n), nrow = n)
X &lt;- matrix(stats::rnorm(m * n), nrow = m, ncol = n)
y_true &lt;- X %*% beta_true
eps &lt;- matrix(stats::rnorm(m), nrow = m)</code></pre>
<p>We will randomly flip the sign of some responses to illustrate the robustness.</p>
<pre class="r"><code>factor &lt;- 2*stats::rbinom(m, size = 1, prob = 1-p) - 1
y &lt;- factor * y_true + eps</code></pre>
<p>We can solve this problem both using ordinary least squares and huber regression to compare.</p>
<pre class="r"><code>suppressMessages(suppressWarnings(library(CVXR)))
beta &lt;- Variable(n)
rel_err &lt;- norm(beta - beta_true, &quot;F&quot;) / norm(beta_true, &quot;F&quot;)

## OLS
obj &lt;- sum((y - X %*% beta)^2)
prob &lt;- Problem(Minimize(obj))
result &lt;- solve(prob)
beta_ols &lt;- result$getValue(beta)
err_ols &lt;- result$getValue(rel_err)

## Solve Huber regression problem
obj &lt;- sum(CVXR::huber(y - X %*% beta, M))
prob &lt;- Problem(Minimize(obj))
result &lt;- solve(prob)
beta_hub &lt;- result$getValue(beta)
err_hub &lt;- result$getValue(rel_err)</code></pre>
<p>Finally, we also solve the OLS problem assuming we know the flipped signs.</p>
<pre class="r"><code>## Solve ordinary least squares assuming sign flips known
obj &lt;- sum((y - factor*(X %*% beta))^2)
prob &lt;- Problem(Minimize(obj))
result &lt;- solve(prob)
beta_prs &lt;- result$getValue(beta)
err_prs &lt;- result$getValue(rel_err)</code></pre>
<p>We can now plot the fit against the measured responses.</p>
<pre class="r"><code>library(ggplot2)
d1 &lt;- data.frame(X = X, y = y, sign = as.factor(factor))
d2 &lt;- data.frame(X = rbind(X, X, X),
                 yHat = rbind(X %*% beta_ols,
                              X %*% beta_hub,
                              X %*% beta_prs),
                 Estimate = c(rep(&quot;OLS&quot;, m),
                              rep(&quot;Huber&quot;, m),
                              rep(&quot;Prescient&quot;, m)))
ggplot() +
    geom_point(data = d1, mapping = aes(x = X, y = y, color = sign)) +
    geom_line(data = d2, mapping = aes(x = X, y = yHat, color = Estimate))</code></pre>
<p><img src="/post/examples/cvxr_huber-regression_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>As can be seen, the Huber line is closer to the prescient line.</p>
</div>
<div id="session-info" class="section level2">
<h2>Session Info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.4.2 (2017-09-28)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.1
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] methods   stats     graphics  grDevices datasets  utils     base     
## 
## other attached packages:
## [1] ggplot2_2.2.1 CVXR_0.94-4  
## 
## loaded via a namespace (and not attached):
##  [1] gmp_0.5-13.1      Rcpp_0.12.14      compiler_3.4.2   
##  [4] plyr_1.8.4        R.methodsS3_1.7.1 R.utils_2.6.0    
##  [7] tools_3.4.2       digest_0.6.12     bit_1.1-12       
## [10] evaluate_0.10.1   tibble_1.3.4      gtable_0.2.0     
## [13] lattice_0.20-35   rlang_0.1.4       Matrix_1.2-12    
## [16] yaml_2.1.14       blogdown_0.3      Rmpfr_0.6-1      
## [19] ECOSolveR_0.3-2   stringr_1.2.0     knitr_1.17       
## [22] rprojroot_1.2     bit64_0.9-7       grid_3.4.2       
## [25] R6_2.2.2          rmarkdown_1.8     bookdown_0.5     
## [28] magrittr_1.5      backports_1.1.1   scales_0.5.0     
## [31] htmltools_0.3.6   scs_1.1-1         colorspace_1.3-2 
## [34] labeling_0.3      stringi_1.1.6     lazyeval_0.2.1   
## [37] munsell_0.4.3     R.oo_1.21.0</code></pre>
</div>
<div id="source" class="section level2">
<h2>Source</h2>
<p><a href="https://github.com/bnaras/cvxr_docs/blob/master/content/post/examples/cvxr_huber-regression.Rmd">R Markdown</a></p>
</div>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-Huber:1964">
<p>Huber, P. J. 1964. “Robust Estimation of a Location Parameter.” <em>Annals of Mathematical Statistics</em> 35 (1): 73–101.</p>
</div>
</div>
</div>
